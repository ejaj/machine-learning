{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff928604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb8169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "print(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7902549d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768 documents\n",
      "3 categories\n",
      "Extracting features from the dataset using a sparse vectorizer\n",
      "n_samples: 2768, n_features: 35311\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'comp.graphics', 'rec.motorcycles']\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=2017)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "\n",
    "labels = dataset.target\n",
    "\n",
    "print(\"Extracting features from the dataset using a sparse vectorizer\")\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c282f10",
   "metadata": {},
   "source": [
    "***Latent Dirichlet allocation***\n",
    "\n",
    "LDAâ€™s objective is to maximize separation between means of projected topics and minimize variance within each projected topics. So LDA defines each topic as a bag of words by carrying out three steps described below.\n",
    "\n",
    "\n",
    "Step 1: Initialize k clusters and assign each word in the each document to one of k topic.\n",
    "\n",
    "Step 2: Re-assign word to new topic based on a) how is the proportion of words for a document to a topic b) how is the proportion of a topic wide spread across all documents.\n",
    "\n",
    "Step 3: Repeat step 2 until coherent topics are resulted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2a601d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "edu com writes subject lines organization article posting university nntp host don like god uk ca just bike know graphics\n",
      "Topic #1:\n",
      "anl elliptical maier michael_maier qmgate separations imagesetter 5298 unscene appreshed linotronic l300 iici amnesia glued veiw halftone 708 252 dot\n",
      "Topic #2:\n",
      "hl7204 eehp22 raoul vrrend386 qedbbs choung qed daruwala ims kkt briarcliff kiat philabs col op_rows op_cols keeve 9327 lakewood gans\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "total_topics = 3\n",
    "lda = LatentDirichletAllocation(n_components=total_topics, \n",
    "                                max_iter=100,\n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,\n",
    "                                random_state=2017)\n",
    "lda.fit(X)\n",
    "\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-20 - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b8bcdf",
   "metadata": {},
   "source": [
    "***Negative Matrix Factorization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "710d4575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "edu god graphics people university don does image believe know just subject lines cs think atheism say organization religion uk\n",
      "Topic #1:\n",
      "sgi keith livesey caltech solntze wpd jon morality com edu moral schneider cco allan objective writes political atheists cruel gap\n",
      "Topic #2:\n",
      "com bike sun ca dod east article writes edu ed like green ride bnr behanna nec organization posting subject dog\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=total_topics, random_state=2017, init='nndsvd', l1_ratio=0.5)\n",
    "nmf.fit(X)\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-20 - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f78532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
